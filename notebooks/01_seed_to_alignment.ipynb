{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l__AMFQsc9cG"
   },
   "source": [
    "# Seed to alignment\n",
    "\n",
    "The seed-to-alignment pipeline takes a small seed dataframe, BLASTs to find sequence hits, performs quality control, lowers alignment redundancy in a taxonomically informed fashion, and generates an alignment.\n",
    "\n",
    "Notebook walks through how to make a seed dataset for use in a topiary analysis, then demonstrates the seed_to_alignment pipeline that takes a seed dataset with a handful of sequences and generates a large multiple sequence alignment.\n",
    "\n",
    "<a href=\"https://githubtocolab.com/harmslab/topiary-examples/blob/main/notebooks/01_seed_to_alignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9UnARLKXydM",
    "tags": []
   },
   "source": [
    "## Setup\n",
    "\n",
    "Run the next two cells to initialize the environment to run topiary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ToKhkGcNoleQ"
   },
   "outputs": [],
   "source": [
    "### THIS CELL SETS UP TOPIARY IN A GOOGLE COLAB ENVIRONMENT. \n",
    "### IF RUNNING THIS NOTEBOOK LOCALLY, IT MAY BE SAFELY DELETED.\n",
    "\n",
    "#@title Install software\n",
    "\n",
    "#@markdown #### Installation requires two steps.\n",
    "\n",
    "#@markdown 1. Install the software by pressing the _Play_ button on the left.\n",
    "#@markdown Please be patient. This will take several minutes. <font color='teal'>\n",
    "#@markdown After the  installation is complete, the kernel will reboot \n",
    "#@markdown and Colab will complain that the session crashed. This is normal.</font>\n",
    "#@markdown <br/>\n",
    "#@markdown 2. After this cell runs, run the \"Initialize environment\" cell that follows.\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    RUNNING_IN_COLAB = True\n",
    "except ImportError:\n",
    "    RUNNING_IN_COLAB = False\n",
    "except Exception as e: \n",
    "    err = \"Could not figure out if runnning in a colab notebook\\n\"\n",
    "    raise Exception(err) from e\n",
    "\n",
    "if RUNNING_IN_COLAB:\n",
    "\n",
    "    import os\n",
    "    os.chdir(\"/content/\")\n",
    "\n",
    "    import urllib.request\n",
    "    urllib.request.urlretrieve(\"https://raw.githubusercontent.com/harmslab/topiary-examples/main/notebooks/colab_installer.py\",\n",
    "                              \"colab_installer.py\")\n",
    "\n",
    "    import colab_installer\n",
    "    colab_installer.install_topiary(install_raxml=False,\n",
    "                                    install_generax=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "XyaNV4CZ8S2t"
   },
   "outputs": [],
   "source": [
    "### IF YOU ARE RUNNING LOCALLY, make sure you activated \n",
    "### the topiary conda environment. (If you did not start this notebook\n",
    "### within that environment, close the session, activate the topiary\n",
    "### environment, and restart). \n",
    "\n",
    "import topiary\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "### EVERYTHING AFTER THIS LINE IS IS USED TO SET UP TOPIARY IN A GOOGLE\n",
    "### COLAB ENVIRONMENT. IF RUNNING THIS NOTEBOOK LOCALLY, THE LINES BELOW\n",
    "### IN THIS CELL MAY BE SAFELY DELETED. \n",
    "\n",
    "#@title Initialize environment\n",
    "\n",
    "#@markdown  Run this cell to initialize the environment after installation.\n",
    "#@markdown (This cell can also be run if the kernel dies during a calculation,\n",
    "#@markdown allowing you to reload modules without having to\n",
    "#@markdown reinstall.) Re-run this cell if you have to re-run any subsequent\n",
    "#@markdown cells so that your calculations are in the correct directory.\n",
    "\n",
    "#@markdown We recommend setting up a working directory on your google drive. This is a \n",
    "#@markdown convenient way to pass files to topiary and will allow you to save\n",
    "#@markdown your work. For example, if you type `topiary_work` into the form\n",
    "#@markdown field below, topiary will save all of its calculations in the \n",
    "#@markdown `topiary_work` directory in MyDrive (i.e. the top directory at\n",
    "#@markdown https://drive.google.com). This script will create the directory if \n",
    "#@markdown it does not already exist. If the directory already exists, any files\n",
    "#@markdown that are already in that directory will be available to topiary. You could, \n",
    "#@markdown for example, put a file called `seed.csv` in `topiary_work` and then\n",
    "#@markdown access it as \"seed.csv\" in all cells below.\n",
    "#@markdown <br/><br/>\n",
    "#@markdown Note: Google may prompt you for permission to access the drive. \n",
    "#@markdown To work in a temporary colab environment, leave this blank. \n",
    "\n",
    "# Select a working directory on google drive\n",
    "google_drive_directory = \"\" #@param {type:\"string\"}\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    RUNNING_IN_COLAB = True\n",
    "except ImportError:\n",
    "    RUNNING_IN_COLAB = False\n",
    "except Exception as e: \n",
    "    err = \"Could not figure out if runnning in a colab notebook\\n\"\n",
    "    raise Exception(err) from e\n",
    "\n",
    "if RUNNING_IN_COLAB:\n",
    "\n",
    "    import os\n",
    "    os.chdir(\"/content/\")\n",
    "\n",
    "    topiary._in_notebook = \"colab\"\n",
    "    import colab_installer\n",
    "    colab_installer.initialize_environment()\n",
    "    colab_installer.mount_google_drive(google_drive_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6O6OTyZtxL8A",
    "tags": []
   },
   "source": [
    "## Construct a seed dataset\n",
    "The first step in a topiary ASR calculation is to construct a seed dataset. This dataset defines protein family members of interest and the distribution of these proteins across species. Topiary uses this seed dataset to automatically find and download sequences to put into the alignment and, ultimately, evolutionary tree. An example for the LY86/LY96 protein family, a pair of closely related innate immune proteins, is shown below. \n",
    "\n",
    "name | species      | sequence   | aliases\n",
    "---- | ------------ | ---------- | -------------------------------------------------------------------------------------------\n",
    "LY96 | Homo sapiens | MLPFLFF... | ESOP1;Myeloid Differentiation Protein-2;MD-2;lymphocyte antigen 96;LY-96\n",
    "LY96 | Danio rerio  | MALWCPS... | ESOP1;Myeloid Differentiation Protein-2;MD-2;lymphocyte antigen 96;LY-96\n",
    "LY86 | Homo sapiens | MKGFTAT... | Lymphocyte Antigen 86;LY86;Myeloid Differentiation Protein-1;MD-1;RP105-associated 3;MMD-1\n",
    "LY86 | Danio rerio  | MKTYFNM... | Lymphocyte Antigen 86;LY86;Myeloid Differentiation Protein-1;MD-1;RP105-associated 3;MMD-1\n",
    "\n",
    "[Download the full spreadsheet](https://topiary-asr.readthedocs.io/en/latest/_static/data/seed-dataframe_example.csv)\n",
    "\n",
    "### To prepare the table:\n",
    "\n",
    "We present this briefly here. For details see the [topiary documentation](https://topiary-asr.readthedocs.io/en/latest/protocol.html).\n",
    "\n",
    "1. **Choose the proteins of interest for your ASR calculation.** In our example, we included two paralogs: LY86 and LY96. The choice of proteins sets the scope of the evolutionary study. To study the deepest ancestor of LY86, we want to include LY96 as the relevant outgroup. In our experience, you generally want ~1-5 paralogs for a robust ASR investigation. As you add more paralogs, you need more sequences to resolve the evolutionary tree, slowing the calculation and—eventually—making the problem computationally intractable.\n",
    "2. **Determine the taxonomic distribution of the protein family.** LY86 and LY96 are found across bony vertebrates (humans and bony fishes, but not sharks). If you are unsure of the taxonomic distribution of your proteins of interest, we discuss BLAST strategies for asking this question in the online [topiary documentation](https://topiary-asr.readthedocs.io/en/latest/protocol.html#determine-what-sequences-to-include).\n",
    "3. **Choose two or three key species with well-annotated genomes that span the whole taxonomic distribution of your proteins of interest.** For LY86 and LY96, we selected humans and zebrafish, covering the breadth of species over which these proteins are found. Choosing humans and chimps would be a poor choice, as this covers only primates; even choosing humans and chickens would be non-optimal, as this covers only amniotes.\n",
    "4. **Add sequences for each protein from your key species to the table.** These sequences are the basis for automatic dataset construction; they should therefore be high quality sequences: canonical rather than isoform, not hypothetical, not partial, etc. Our usual source for these seed sequences is Uniprot, but these can come from any source.\n",
    "5. **Compile a list of aliases for each protein.** The same protein can have different names across different databases and species. Even in the same genome, gene nomenclature can be inconsistent. By using a human-curated list of aliases, topiary is more effective at identifying sequences that truly correspond to the paralogs of interest. Aliases can be found in many online databases. (A list of databases is given in the online documentation).\n",
    "\n",
    "### Load the table\n",
    "\n",
    "Run the following cell to load your seed dataframe into the variable `seed_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "8DVuCAZmmAnt"
   },
   "outputs": [],
   "source": [
    "### IF RUNNING LOCALLY: set `seed_dataset =` to point to your desired csv or xlsx file. \n",
    "### Alternatively, you can set a `seed_df` to point to a pandas dataframe holding the\n",
    "### seed dataset. \n",
    "\n",
    "seed_dataset = \"https://raw.githubusercontent.com/harmslab/topiary-examples/main/data/ly86-ly96.csv\"\n",
    "seed_df = None\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# COLAB SPECIFIC BLOCK\n",
    "\n",
    "#@title Load seed dataset\n",
    "\n",
    "#@markdown Before running this cell, specify either: \n",
    "#@markdown + A file containing a seed dataset in your working\n",
    "#@markdown directory (your google drive specified above).\n",
    "#@markdown The default input file is an example LY86/LY96 seed dataset.\n",
    "#@markdown + Select `upload_file` to upload a file directly from your computer. \n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    RUNNING_IN_COLAB = True\n",
    "except ImportError:\n",
    "    RUNNING_IN_COLAB = False\n",
    "except Exception as e: \n",
    "    err = \"Could not figure out if runnning in a colab notebook\\n\"\n",
    "    raise Exception(err) from e\n",
    "\n",
    "if RUNNING_IN_COLAB:\n",
    "\n",
    "    seed_dataset = \"https://raw.githubusercontent.com/harmslab/topiary-examples/main/data/ly86-ly96.csv\" #@param {type:\"string\"}\n",
    "    upload_file = False #@param {type:\"boolean\"}\n",
    "\n",
    "    if issubclass(type(seed_dataset),str):\n",
    "        seed_dataset = seed_dataset.strip()\n",
    "\n",
    "    if seed_dataset != \"\" and upload_file:\n",
    "        err = \"Please give a seed_dataset OR select upload file\\n\"\n",
    "        raise ValueError(err)\n",
    "\n",
    "    if seed_dataset == \"\" and not upload_file:\n",
    "        err = \"Please either give a seed_dataset or select upload file\\n\"\n",
    "        raise ValueError(err)\n",
    "\n",
    "    if upload_file:\n",
    "\n",
    "        try:\n",
    "            from google.colab import files\n",
    "            uploaded_files = files.upload()\n",
    "            keys = list(uploaded_files.keys())\n",
    "            seed_dataset = keys[0] #uploaded_files[keys[0]]\n",
    "        except ImportError:\n",
    "            pass\n",
    "\n",
    "# END COLAB SPECIFIC BLOCK\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "if seed_df is None:\n",
    "\n",
    "    try:\n",
    "        seed_df = pd.read_csv(seed_dataset)\n",
    "    except:\n",
    "        try:\n",
    "            seed_df = pd.read_excel(seed_dataset)\n",
    "        except:\n",
    "            err = f\"Could not read {seed_dataset}. This should be a csv or xlsx file\\n\"\n",
    "            raise ValueError(err)\n",
    "\n",
    "seed_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yj9QUQvK8OqK"
   },
   "source": [
    "## Seed-to-alignment\n",
    "\n",
    "The seed dataset is passed directly into the topiary seed-to-alignment pipeline. This script uses BLAST to build a dataset of thousands of protein sequences, performs quality control, lowers alignment redundancy in a taxonomically informed fashion, and then generates an alignment of sequences. This generally takes less than an hour on a modern laptop. The slowest step in this pipeline is often the initial NCBI BLAST step. If your connection is unstable or the NCBI server proves too slow, topiary can BLAST against local databases or load previously saved BLAST XML results into this script -- as long as you have uploaded these files into your working directory.\n",
    "\n",
    "This script will generate and save a series of spreadsheets, eeach capturing the state of the dataset at each step in the pipeline. The final output consists of a single spreadsheet (`05_clean-aligned-dataframe.csv`) and a single fasta file (`06_alignment.fasta`) holding the alignment. The results can be found in the accessed in the `out_dir` folder (`seed-to-ali` by default).\n",
    "\n",
    "For a full description of the meanings of all parameters, see the [topiary documentation](https://topiary-asr.readthedocs.io/en/latest/topiary.pipeline.html#module-topiary.pipeline.seed_to_alignment).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ivWIlbNdGHn2"
   },
   "outputs": [],
   "source": [
    "#@title Run the seed-to-alignment script\n",
    "\n",
    "#@markdown Please execute this cell by pressing the _Play_ button\n",
    "#@markdown to run the full seed-to-alignment pipeline.\n",
    "\n",
    "# parameters                  # google colab parameter selectors\n",
    "out_dir = \"seed-to-ali\"         #@param {type:\"string\"}\n",
    "seqs_per_column = 1             #@param {type:\"number\"}\n",
    "max_seq_number = 500            #@param {type:\"integer\"}\n",
    "redundancy_cutoff = 0.90        #@param {type:\"number\"}\n",
    "worst_align_drop_fx = 0.1       #@param {type:\"number\"}\n",
    "sparse_column_cutoff = 0.80     #@param {type:\"number\"}\n",
    "align_trim_first = 0.05         #@param {type:\"number\"}\n",
    "align_trim_last = 0.95          #@param {type:\"number\"}\n",
    "\n",
    "force_species_aware = False     #@param {type:\"boolean\"}\n",
    "force_not_species_aware = False #@param {type:\"boolean\"}\n",
    "\n",
    "ncbi_blast_db = None            #@param {type:\"string\"}\n",
    "local_blast_db = None           #@param {type:\"string\"}\n",
    "blast_xml = None                #@param {type:\"string\"}\n",
    "\n",
    "move_mrca_up_by = 2             #@param {type:\"integer\"}\n",
    "local_recip_blast_db = None     #@param {type:\"string\"}\n",
    "min_call_prob = 0.95            #@param {type:\"slider\", min:0.01, max:0.99, step:0.01}\n",
    "partition_temp = 1              #@param {type:\"number\"}\n",
    "\n",
    "hitlist_size = 5000             #@param {type:\"integer\"}\n",
    "e_value_cutoff = 0.001          #@param {type:\"number\"}\n",
    "gapcost_gap_exists = 11         #@param {type:\"integer\"}\n",
    "gapcost_per_residue = 1         #@param {type:\"integer\"}\n",
    "num_ncbi_blast_threads = 1      #@param {type:\"integer\"}\n",
    "num_local_blast_threads = -1    #@param {type:\"integer\"}\n",
    "\n",
    "restart = False                 #@param {type:\"boolean\"}\n",
    "overwrite = False               #@param {type:\"boolean\"}\n",
    "keep_recip_blast_xml = False    #@param {type:\"boolean\"}\n",
    "\n",
    "df = topiary.seed_to_alignment(seed_df=seed_df,\n",
    "                               out_dir=out_dir,\n",
    "                               seqs_per_column=seqs_per_column,\n",
    "                               max_seq_number=max_seq_number,\n",
    "                               redundancy_cutoff=redundancy_cutoff,\n",
    "                               worst_align_drop_fx=worst_align_drop_fx,\n",
    "                               sparse_column_cutoff=sparse_column_cutoff,\n",
    "                               align_trim=(align_trim_first,align_trim_last),\n",
    "                               ncbi_blast_db=ncbi_blast_db,\n",
    "                               local_blast_db=local_blast_db,\n",
    "                               blast_xml=blast_xml,\n",
    "                               move_mrca_up_by=move_mrca_up_by,\n",
    "                               local_recip_blast_db=local_blast_db, \n",
    "                               min_call_prob=min_call_prob,\n",
    "                               partition_temp=partition_temp,\n",
    "                               hitlist_size=hitlist_size,\n",
    "                               e_value_cutoff=e_value_cutoff,\n",
    "                               gapcosts=(gapcost_gap_exists,gapcost_per_residue),\n",
    "                               num_ncbi_blast_threads=num_ncbi_blast_threads,\n",
    "                               num_local_blast_threads=num_local_blast_threads,\n",
    "                               restart=restart,\n",
    "                               overwrite=overwrite,\n",
    "                               keep_recip_blast_xml=keep_recip_blast_xml)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kFwKcI1-rtX"
   },
   "source": [
    "## Inspect and edit alignment\n",
    "\n",
    "Before reconstructing a phylogenetic tree and ancestors, we strongly recommend inspecting and possibly editing the alignment. There are a variety of pieces of software for visualizing alignments, including AliView (Larsson A, 2014), JALView (Waterhouse AM, 2009), and MEGA (Tamura K, 2021). We generally use AliView because of its balance of utility and simplicity.\n",
    "\n",
    "### Load the alignment fasta file in an alignment editor\n",
    "\n",
    "To edit the alignment load `06_alignment.fasta` in an alignment editor. This will be in the directory you specified for `out_dir` above. \n",
    "If running on Google Colab, download the `06_alignment.fasta` file onto your computer. Click on the folder icon on the Colab menu on the left side of the window. Navigate into the seed-to-ali folder (or the name you gave your output directory in the previous step), hover over `06_alignment.fasta`, click on the three dots to the right and choose `Download`. If you mounted your Google Drive it will be in `gdrive/MyDrive/seed-to-ali`, and also be accessible directly on your Google Drive. \n",
    "\n",
    "### (Possibly) edit the alignment\n",
    "\n",
    "There are differing views on whether to manually edit an alignment (e.g. [Catanach 2019](https://peerj.com/articles/6142/) vs. [Morrison 2006](https://doi.org/10.1071/SB06020)); the topiary package allows a user to manually edit their alignment but does not require it. We generally recommend making a few adjustments to alignments. Importantly, if we edit an alignment, we publish the alignment as supplemental material in the resulting manuscript so others can reproduce our work. \n",
    "\n",
    "IMPORTANT: when editing an alignment, *do not change the names of the sequences* as this is how topiary maps the alignment back into the dataframe. Also, *do not add sequences to the alignment*. (To add sequences, you should add them to the dataframe itself before writing out the alignment. See the advanced topiary notebook in the https://github.com/harmslab/topiary-examples for how to do so.)\n",
    "\n",
    "When editing up alignments, we use the four \"moves\" listed below (see the [documentation](https://topiary-asr.readthedocs.io/en/latest/protocol.html#visually-inspect-and-possibly-edit-the-alignment) for detailed instructions and examples).\n",
    "\n",
    "1. Trim variable-length N- and C-terminal regions from the alignment. A huge number of sparse and variable columns will slow evolutionary analyses and will generally not provide enough signal to be reconstructed with confidence.\n",
    "2. Delete sequences with long, unique insertions or deletions (indels). Indels can lead to alignment ambiguity around flanking regions. Further, they provide no information for most ancestors, most of whom do not have the indel, while increasing the computational cost of the phylogenetic analysis. Note, we do not make internal edits to sequences (say, by deleting a long lineage-specific insertion) as this becomes difficult to track or justify upon future realignment steps.\n",
    "3. Delete lineage-specific duplicates, selecting the sequence with the greatest sequence coverage. The pipeline generally does a good job of deleting sequences in this class; however, if such sequences slip through, we delete them from the alignment. Because trying to align long, unique, and variable sequences can affect the alignment of other sequences, we generally use Muscle5 to re-align the full MSA after we perform steps 1-3. This can be done directly from AliView. (We will often iterate through steps 1-3 and full alignment several times.)\n",
    "4. Finally, after we are satisfied that we have sequences of reasonable length and composition, we carefully inspect the alignment and may correct “obvious” local misalignments. In our view, these edits makes the alignment a more accurate description of sequence homology than otherwise; however, we recognize that this is subjective and difficult to quantify. As noted above, we publish our alignment with our final ancestors to allow others to assess our judgement and promote reproducibility.\n",
    "\n",
    "### Save your alignment and read back into the topiary dataframe\n",
    "\n",
    "If you edited the alignment in the editor, save that edited alignment out as a `.fasta` file. \n",
    "\n",
    "### Read the edited alignment back into the topiary dataframe\n",
    "If you made edits to the alignment, it needs to be read back into the topiary dataframe to infer ancestors. You have a two options to do this. \n",
    "\n",
    "+ Run the following cell. Change `aligned_dataframe` and `edited_fasta_file` to point to the relevant files. This will create an output file with the name specified in `output_file_name`. (If you are running on Google Colab, you should upload your edited fasta file to the relevant directory on your Google Drive). \n",
    "+ If you are using a cluster to do the ancestral inference steps (recommended), you can upload both your edited alignment and the topiary dataframe from the last step up to the cluster. You can then run a command line script: `topiary-fasta-into-dataframe 05_clean-aligned-dataframe.csv edited_alignment.fasta final-dataframe.csv`. This will create a new file (`final-dataframe.csv`) that can be fed into subsequent analyses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "9lpsoH3Tz7iW"
   },
   "outputs": [],
   "source": [
    "#@title Load the topiary spreadsheet\n",
    "\n",
    "previous_dataframe = \"seed-to-ali/05_clean-aligned-dataframe.csv\" #@param {type: \"string\"}\n",
    "edited_fasta_file = \"edited-alignment.fasta\"                      #@param {type: \"string\"}\n",
    "output_file_name = \"final-dataframe.csv\"                          #@param {type: \"string}\"\n",
    "\n",
    "df = topiary.read_dataframe(previous_dataframe)\n",
    "alignment_df = topiary.read_fasta_into(df,edited_fasta_file)\n",
    "topiary.write_dataframe(alignment_df,output_file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete!\n",
    "\n",
    "You should now have a spreadsheet (i.e. `final-dataframe.csv`) that has all of your sequences aligned, with meta-data. This is the only required input for the next step. We strongly recommend including this dataframe as a supplemental file in a manuscript using topiary, as it has accessions, sequences, and the alignment necessary for others to reproduce your work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### seed_to_alignment parameter descriptions\n",
    "----------\n",
    "\n",
    "+ **seed_df** : *str*\n",
    "<br> Spreadsheet with at least four columns: name, species, sequence, and aliases. This spreadsheet will be read in as a pandas.DataFrame. See [documentation](https://topiary-asr.readthedocs.io/en/latest/data_structures.html#seed-dataframe) on seed dataframes for details.\n",
    "\n",
    "+ **out_dir** : *str, optional*\n",
    "<br> An output directory to save results into. If not specified, creates an output directory with the format `seed_to_alignment_{randomletters}`.\n",
    "\n",
    "+ **seqs_per_column** : *float, default=1*\n",
    "<br> Aim to have this number of sequences per column in the key species sequences. (For example, if the key sequence is 100 amino acids long, seqs_per_column=1 would aim for 100 sequences; 2 would aim for 200 sequences).\n",
    "\n",
    "+ **max_seq_number** : *int, default=500*\n",
    "<br> Maximum number of sequences to get, regardless of `seqs_per_column` and lengths of sequences in seed dataframe.\n",
    "\n",
    "+ **redundancy_cutoff** : *float, default=0.90*\n",
    "<br> Merge sequences from closely related species with sequence identity above cutoff.\n",
    "\n",
    "+ **worst_align_drop_fx** : *float, default=0.1*\n",
    "<br> After alignment, drop approximately this fraction of the sequences, selecting those that have long insertions and are missing chunks of sequences.\n",
    "\n",
    "+ **sparse_column_cutoff** : *float, default=0.80*\n",
    "<br> When checking alignment quality, a column is sparse if it has gaps in more than `sparse_column_cutoff` sequences.\n",
    "\n",
    "+ **align_trim** : *tuple, default=(0.05,0.95)*\n",
    "<br> When checking alignment quality, do not score the first and last parts of the alignment. These are often non-coding and highly variable. Interpreted like a slice, but with percentages. `(0.0,1.0)` would use 100% of the alignment to score quality; `(0.05,0.98)` would only score quality of the alignment after the first 0.05 up until the last 0.02 from the end.\n",
    "<br>\n",
    "\n",
    "+ **ncbi_blast_db** : *str, optional*\n",
    "<br> NCBI BLAST database to use. (If `ncbi_blast_db`, `local_blast_db` and `blast_xml` are all None, `ncbi_blast_db` is automatically set to \"nr\").\n",
    "\n",
    "+ **local_blast_db** : *str, optional*\n",
    "<br> Local BLAST database to use.\n",
    "\n",
    "+ **blast_xml** : *str or list, optional*\n",
    "<br> Previously generated BLAST .xml files to load. This argument can be:\n",
    "  + single .xml file (str)\n",
    "  + list of .xml files (list of str)\n",
    "  + directory (str). Topiary will load all .xml files in the directory.\n",
    "<br>\n",
    "\n",
    "+ **move_mrca_up_by** : *int, default=2*\n",
    "<br> When inferring the phylogenetic context from the seed dataframe, get the most recent common ancestor of the seed species, then find the taxonomic rank `move_mrca_up_by` levels above that ancestor. For example, if the key species all come from marsupials (Theria) and `move_mrca_up_by == 2`, the context will be Amniota (Theria -> Mammalia -> Amniota). Note: if all species in the dataset are bacteria or archaea, this argument is ignored and the context will be set to `Bacteria` or `Archaea`. \n",
    "\n",
    "+ **local_recip_blast_db** : *str, optional*\n",
    "<br> Local BLAST database to use for reciprocal BLAST. If None, construct a reciprocal BLAST database by downloading the proteomes of the key species from NCBI. \n",
    "\n",
    "+ **min_call_prob** : *float, default=0.95*\n",
    "<br> Hits from all paralogs that yield a regular expression match to one of the aliases from the seed dataframe are weighted by their relative BLAST bit scores. Each paralog is assigned a relative probability. This cutoff is the minimum probability the best paralog match must have to result in a paralog call. Value should be between 0 and 1 (not inclusive), where increasing min_call_prob increases the stringency.\n",
    "\n",
    "+ **partition_temp** : *float, default=1*\n",
    "<br> When calculating posterior probability of the reciprocal BLAST paralog call, use this for weighting: `2^(bit_score/partition_temp)`. `partition_temp` should be a float > 0. A higher value corresponds to a higher stringency. (The bit score difference between the best hit and the bit scores of other hits would have to be higher to be significant). This is a minimum value. It may be adjusted automatically to avoid numerical problems in the calculation.\n",
    "<br>\n",
    "\n",
    "+ **hitlist_size** : *int, default=5000*\n",
    "<br> Download only the top `hitlist_size` hits in initial BLAST.\n",
    "\n",
    "+ **e_value_cutoff** : *float, default=0.001*\n",
    "<br> Only take hits with e-value better than `e_value_cutoff` in initial BLAST.\n",
    "\n",
    "+ **gapcost** : *tuple (a,b), default=(11,1)* \n",
    "<br> BLAST gapcosts (length 2 tuple of ints) in initial BLAST. The raw score of an alignment is the sum of the scores for aligning pairs of residues and the scores for gaps. This BLAST search will charge a score -a for the existence of a gap, and the score -b for each residue in the gap. Thus a gap of k residues receives a total score of -(a+bk). The default (11,1) would provide scores -(11+1k) for each gap with k residues.\n",
    "\n",
    "+ **num_ncbi_blast_threads** : *int, default=1*\n",
    "<br> Number of threads to use for NCBI BLAST. -1 means use all available. (Note that multithreading rarely speeds up remote BLAST).\n",
    "\n",
    "+ **num_local_blast_threads** : *int, default=-1*\n",
    "<br> Number of threads to use for local BLAST. -1 means all available.\n",
    "<br>\n",
    "\n",
    "+ **restart** : *bool, default=False*\n",
    "<br> Restart job from where it stopped in output directory. Incompatible with overwrite. This argument requires specifying a value for `out_dir`.\n",
    "\n",
    "+ **overwrite** : *bool, default=False*\n",
    "<br> Overwrite `out_dir` if it already exists. Incompatible with restart.\n",
    "\n",
    "+ **keep_recip_blast_xml** : *bool, default=False*\n",
    "<br> Whether or not to keep raw BLAST .xml output.\n",
    "\n",
    "+ **verbose** : *bool, default=False*\n",
    "<br> Verbosity of output.\n",
    "<br>\n",
    "\n",
    "### Returns\n",
    "----------\n",
    "+ **topiary_dataframe** : *pandas.DataFrame*\n",
    "<br> Topiary dataframe with aligned, quality-controlled sequences.\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
