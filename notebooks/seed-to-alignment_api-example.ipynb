{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3764585",
   "metadata": {
    "id": "e3764585"
   },
   "source": [
    "# Seed-to-alignment in steps\n",
    "\n",
    "<a href=\"https://githubtocolab.com/harmslab/topiary-examples/blob/main/notebooks/seed-to-alignment_api-example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "This notebook breaks the seed-to-alignment pipeline into individual steps. The goals for this notebook are:\n",
    "1. Help users understand what topiary is doing in this pipeline.d\n",
    "2. Provide a starting point for users to customize specific aspects of the pipeline.\n",
    "3. Demonstrate the topiary API so users can develop their own pipelines. \n",
    "\n",
    "The seed-to-alignment pipeline takes a seed dataframe, BLASTs to find homologs, identifies orthologs by reciprocal BLAST, performs sequence quality control, lowers sequence redundancy, and generates a final alignment. This notebook recapitulates the steps run with a single function call in the *01_seed_to_alignment.ipynb* XX notebook or `topiary-seed-to-alignment` script.\n",
    "\n",
    "\n",
    "## API introduction\n",
    "The basic idea of the topiary API is to have each function take a topiary\n",
    "dataframe as an argument and to then return a modified *copy* of that dataframe\n",
    "as an output. This allows one to write pipelines, as well as easily save out\n",
    "intermediate steps. The basic flow goes something like:\n",
    "\n",
    "```\n",
    "df = topiary.do_something(df,args)\n",
    "topiary.write_dataframe(df,\"current-state.csv\")\n",
    "```\n",
    "The main topiary functions take a topiary dataframe as their first argument,\n",
    "other arguments needed by the function, and then return an appropriately\n",
    "modified copy of the dataframe. Topiary functions generally modify dataframes by\n",
    "adding columns with new information and/or by setting the `keep` column to\n",
    "`True` or `False`. The modified dataframe can then be written out to\n",
    "a csv file to preserve the current state of the dataframe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OO4OkXjcIP2r",
   "metadata": {
    "id": "OO4OkXjcIP2r"
   },
   "source": [
    "## Set up the environment\n",
    "\n",
    "Run the next two cells to initialize the environment to run topiary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MvCzcvUfFX04",
   "metadata": {
    "cellView": "form",
    "id": "MvCzcvUfFX04"
   },
   "outputs": [],
   "source": [
    "### THIS CELL SETS UP TOPIARY IN A GOOGLE COLAB ENVIRONMENT. \n",
    "### IF RUNNING THIS NOTEBOOK LOCALLY, IT MAY BE SAFELY DELETED.\n",
    "\n",
    "#@title Install software\n",
    "\n",
    "#@markdown #### Installation requires two steps.\n",
    "\n",
    "#@markdown 1. Install the software by pressing the _Play_ button on the left.\n",
    "#@markdown Please be patient. This will take several minutes. <font color='teal'>\n",
    "#@markdown After the  installation is complete, the kernel will reboot \n",
    "#@markdown and Colab will complain that the session crashed. This is normal.</font>\n",
    "#@markdown <br/>\n",
    "#@markdown 2. After this cell runs, run the \"Initialize environment\" cell that follows.\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    RUNNING_IN_COLAB = True\n",
    "except ImportError:\n",
    "    RUNNING_IN_COLAB = False\n",
    "except Exception as e: \n",
    "    err = \"Could not figure out if runnning in a colab notebook\\n\"\n",
    "    raise Exception(err) from e\n",
    "\n",
    "if RUNNING_IN_COLAB:\n",
    "\n",
    "    import os\n",
    "    os.chdir(\"/content/\")\n",
    "\n",
    "    import urllib.request\n",
    "    urllib.request.urlretrieve(\"https://raw.githubusercontent.com/harmslab/topiary-examples/main/notebooks/colab_installer.py\",\n",
    "                              \"colab_installer.py\")\n",
    "\n",
    "    import colab_installer\n",
    "    colab_installer.install_topiary(install_raxml=False,\n",
    "                                    install_generax=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w-k76NINgu6I",
   "metadata": {
    "cellView": "form",
    "id": "w-k76NINgu6I"
   },
   "outputs": [],
   "source": [
    "### IF YOU ARE RUNNING LOCALLY, make sure you installed topiary and\n",
    "### make sure you activated the topiary conda environment. (If you\n",
    "### did not start this notebook within that environment, close the\n",
    "### session, activate the topiary environment, and restart). \n",
    "\n",
    "import topiary\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "### EVERYTHING AFTER THIS LINE IS IS USED TO SET UP TOPIARY IN A GOOGLE\n",
    "### COLAB ENVIRONMENT. IF RUNNING THIS NOTEBOOK LOCALLY, THE LINES BELOW\n",
    "### IN THIS CELL MAY BE SAFELY DELETED. \n",
    "\n",
    "#@title Initialize environment\n",
    "\n",
    "#@markdown  Run this cell to initialize the environment after installation.\n",
    "#@markdown (This cell can also be run if the kernel dies during a calculation,\n",
    "#@markdown allowing you to reload modules without having to\n",
    "#@markdown reinstall.) Re-run this cell if you have to re-run any subsequent\n",
    "#@markdown cells so that your calculations are in the correct directory.\n",
    "\n",
    "#@markdown We recommend setting up a working directory on your google drive. This is a \n",
    "#@markdown convenient way to pass files to topiary and will allow you to save\n",
    "#@markdown your work. For example, if you type `topiary_work` into the form\n",
    "#@markdown field below, topiary will save all of its calculations in the \n",
    "#@markdown `topiary_work` directory in MyDrive (i.e. the top directory at\n",
    "#@markdown https://drive.google.com). This script will create the directory if \n",
    "#@markdown it does not already exist. If the directory already exists, any files\n",
    "#@markdown that are already in that directory will be available to topiary. You could, \n",
    "#@markdown for example, put a file called `seed.csv` in `topiary_work` and then\n",
    "#@markdown access it as \"seed.csv\" in all cells below.\n",
    "#@markdown <br/><br/>\n",
    "#@markdown Note: Google may prompt you for permission to access the drive. \n",
    "#@markdown To work in a temporary colab environment, leave this blank. \n",
    "\n",
    "# Select a working directory on google drive\n",
    "google_drive_directory = \"\" #@param {type:\"string\"}\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    RUNNING_IN_COLAB = True\n",
    "except ImportError:\n",
    "    RUNNING_IN_COLAB = False\n",
    "except Exception as e: \n",
    "    err = \"Could not figure out if runnning in a colab notebook\\n\"\n",
    "    raise Exception(err) from e\n",
    "\n",
    "if RUNNING_IN_COLAB:\n",
    "\n",
    "    import os\n",
    "    os.chdir(\"/content/\")\n",
    "\n",
    "    topiary._in_notebook = \"colab\"\n",
    "    import colab_installer\n",
    "    colab_installer.initialize_environment()\n",
    "    colab_installer.mount_google_drive(google_drive_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4105ab-3d37-41d8-837b-b5fd0d358a1d",
   "metadata": {},
   "source": [
    "## Construct a seed dataset\n",
    "The first step in a topiary ASR calculation is to construct a seed dataset. This dataset defines protein family members of interest and the distribution of these proteins across species. Topiary uses this seed dataset to automatically find and download sequences to put into the alignment and, ultimately, evolutionary tree. An example for the LY86/LY96 protein family, a pair of closely related innate immune proteins, is shown below. \n",
    "\n",
    "name | species      | sequence   | aliases\n",
    "---- | ------------ | ---------- | -------------------------------------------------------------------------------------------\n",
    "LY96 | Homo sapiens | MLPFLFF... | ESOP1;Myeloid Differentiation Protein-2;MD-2;lymphocyte antigen 96;LY-96\n",
    "LY96 | Danio rerio  | MALWCPS... | ESOP1;Myeloid Differentiation Protein-2;MD-2;lymphocyte antigen 96;LY-96\n",
    "LY86 | Homo sapiens | MKGFTAT... | Lymphocyte Antigen 86;LY86;Myeloid Differentiation Protein-1;MD-1;RP105-associated 3;MMD-1\n",
    "LY86 | Danio rerio  | MKTYFNM... | Lymphocyte Antigen 86;LY86;Myeloid Differentiation Protein-1;MD-1;RP105-associated 3;MMD-1\n",
    "\n",
    "[Download the full spreadsheet](https://raw.githubusercontent.com/harmslab/topiary-examples/main/data/ly86-ly96.csv)\n",
    "\n",
    "For a description of how to prepare this table, see the [topiary documentation](https://topiary-asr.readthedocs.io/en/latest/protocol.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "su1owKB4MpyQ",
   "metadata": {
    "cellView": "form",
    "id": "su1owKB4MpyQ"
   },
   "outputs": [],
   "source": [
    "### IF RUNNING LOCALLY: set `seed_spreadsheet_file =` to point to your desired csv or xlsx file. \n",
    "### Alternatively, you can set a `seed_df` to point to a pandas dataframe holding the\n",
    "### seed dataset. \n",
    "\n",
    "seed_spreadsheet_file = \"https://raw.githubusercontent.com/harmslab/topiary-examples/main/data/ly86-ly96.csv\"\n",
    "seed_df = None\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# COLAB SPECIFIC BLOCK\n",
    "\n",
    "#@title Load seed dataset\n",
    "\n",
    "#@markdown Before running this cell, specify either: \n",
    "#@markdown + A file containing a seed dataset in your working\n",
    "#@markdown directory (your google drive specified above).\n",
    "#@markdown The default input file is an example LY86/LY96 seed dataset.\n",
    "#@markdown + Select `upload_file` to upload a file directly from your computer. \n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    RUNNING_IN_COLAB = True\n",
    "except ImportError:\n",
    "    RUNNING_IN_COLAB = False\n",
    "except Exception as e: \n",
    "    err = \"Could not figure out if runnning in a colab notebook\\n\"\n",
    "    raise Exception(err) from e\n",
    "\n",
    "if RUNNING_IN_COLAB:\n",
    "\n",
    "    seed_spreadsheet_file = \"https://raw.githubusercontent.com/harmslab/topiary-examples/main/data/ly86-ly96.csv\" #@param {type:\"string\"}\n",
    "    upload_file = False #@param {type:\"boolean\"}\n",
    "\n",
    "    if issubclass(type(seed_spreadsheet_file),str):\n",
    "        seed_spreadsheet_file = seed_spreadsheet_file.strip()\n",
    "\n",
    "    if seed_spreadsheet_file != \"\" and upload_file:\n",
    "        err = \"Please give a seed_spreadsheet_file OR select upload file\\n\"\n",
    "        raise ValueError(err)\n",
    "\n",
    "    if seed_spreadsheet_file == \"\" and not upload_file:\n",
    "        err = \"Please either give a seed_spreadsheet_file or select upload file\\n\"\n",
    "        raise ValueError(err)\n",
    "\n",
    "    if upload_file:\n",
    "\n",
    "        try:\n",
    "            from google.colab import files\n",
    "            uploaded_files = files.upload()\n",
    "            keys = list(uploaded_files.keys())\n",
    "            seed_spreadsheet_file = keys[0] #uploaded_files[keys[0]]\n",
    "        except ImportError:\n",
    "            pass\n",
    "\n",
    "# END COLAB SPECIFIC BLOCK\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Read seed_df from the input file\n",
    "if seed_df is None:\n",
    "\n",
    "    try:\n",
    "        seed_df = pd.read_csv(seed_spreadsheet_file)\n",
    "    except:\n",
    "        try:\n",
    "            seed_df = pd.read_excel(seed_spreadsheet_file)\n",
    "        except:\n",
    "            err = f\"Could not read {seed_spreadsheet_file}. This should be a csv or xlsx file\\n\"\n",
    "            raise ValueError(err)\n",
    "\n",
    "seed_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080fe002",
   "metadata": {
    "id": "080fe002"
   },
   "source": [
    "## Construct an initial dataset using BLAST\n",
    "\n",
    "At this point, we have a seed dataset as a pandas DataFrame (`seed_df`; see output of last cell). For the next step, we BLAST against user-specified database(s) to find homologs of the proteins in our seed dataset. \n",
    "\n",
    "### Inputs:\n",
    "+ `seed_df`: The only required input to the following function is the seed dataframe.\n",
    "+ Other arguments to this function give the user control over how BLASTing is done. For information about these parameters, see the [topiary documentation](https://topiary-asr.readthedocs.io/en/latest/topiary.io.html#topiary.io.seed.df_from_seed).\n",
    "\n",
    "### Outputs:\n",
    "+ `df`: A new topiary dataframe with the BLAST hits given by the sequences in `seed_df`. \n",
    "+ `key_species`: A list of the key species in the seed dataframe.\n",
    "+ `paralog_patterns`: A dictionary of [regular expressions](https://docs.python.org/3/library/re.html) that allow topiary to look for reciprocal BLAST hits that match the paralog aliases from the see dataframe. See documentation on [paralog patterns](https://topiary-asr.readthedocs.io/en/latest/data_structures.html#paralog-patterns) for details on this dictionary.\n",
    "+ `species_aware`: Whether or not to do the remaining analysis in a species-aware fashion. By default, the analysis will be species aware for non-microbial datasets and not be species aware for microbial datasets. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068d5baf",
   "metadata": {
    "id": "068d5baf"
   },
   "outputs": [],
   "source": [
    "# These function arguments are the default values. The function should run with these\n",
    "# values. For more information about the parameters, see:\n",
    "# https://topiary-asr.readthedocs.io/en/latest/topiary.io.html#topiary.io.seed.df_from_seed\n",
    "\n",
    "df, key_species, paralog_patterns, species_aware = topiary.df_from_seed(seed_df=seed_df,\n",
    "                                                                        ncbi_blast_db=\"nr\",\n",
    "                                                                        local_blast_db=None,\n",
    "                                                                        blast_xml=None,               \n",
    "                                                                        move_mrca_up_by=2,\n",
    "                                                                        species_aware=None,\n",
    "                                                                        hitlist_size=5000,            \n",
    "                                                                        e_value_cutoff=0.001,         \n",
    "                                                                        gapcosts=(11,1),\n",
    "                                                                        num_ncbi_blast_threads=1,       \n",
    "                                                                        num_local_blast_threads=-1,\n",
    "                                                                        keep_blast_xml=False)  \n",
    "    \n",
    "# Save out the dataframe so we can keep track of our changes. \n",
    "topiary.write_dataframe(df,\"01_initial-dataframe.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_Eofl3tfskPS",
   "metadata": {
    "id": "_Eofl3tfskPS"
   },
   "source": [
    "### Things to look for in your output dataframe:\n",
    "\n",
    "1. The dataframe has your seed sequences plus the BLAST results. (There should be *a lot* more sequences than your seed dataframe).\n",
    "2. If you scroll to the right, there is a ton of information about each sequence (accession, sequence, e_value, etc.). The columns of the dataframe can be accessed using the command `df.columns`.\n",
    "3. The `keep` column is special. Topiary does not delete sequences from the analysis, but instead sets `keep = False` for sequences that do not pass quality control. All sequences should have `keep = True` at the moment because we have not done quality control yet.\n",
    "4. The sequences from your seed dataframe are at the top of this output dataframe. They have two columns set to `True`: `always_keep` (meaning they will not be deleted) and `key_species` (meaning they are from a key species). **PRO TIP**: If you want to make sure a sequence is not deleted, you can set `always_keep = True` for that sequence and topiary will not delete it, regardless of downstream quality control steps. \n",
    "5. The `ott` and `resolvable` columns indicate the species identifier on the Open Tree of Life database (`ott`) and whether the species can be unambiguously placed on a species tree (`resolvable`). For a species aware reconstruction, only sequences with `resolvable = True` can be included in the main phylogenetic analysis. \n",
    "\n",
    "## Identify each hit by reciprocal BLAST\n",
    "\n",
    "Once the initial dataset is constructed, topiary identifies each hit by reciprocal BLAST. The cell below downloads the proteomes for the key species from the NCBI, constructs a local BLAST databse, and then uses each BLAST hit from above as a query against this BLAST database from the key species. It then identifies hits whose descriptions match the text patterns from `paralog_pattern` generated above. Any sequence that does not match at least one pattern has `keep` set to `False` as the sequence is likely a paralog rather than ortholog to at least one of the sequences in the seed dataset. \n",
    "\n",
    "### Inputs:\n",
    "+ This cell uses three inputs from the previous cell:\n",
    "    + `df`: The topiary dataframe holding the BLAST hits. \n",
    "    + `key_species`: The key species in your dataset.\n",
    "    + `paralog_patterns`: A dictionary of regular expressions used to search the key proteomes from reciprocal BLAST hits.\n",
    "+ For detailed descriptions of the arguments to the three functions used, see the documentation:\n",
    "    + [topiary.ncbi.get_proteome](https://topiary-asr.readthedocs.io/en/latest/topiary.ncbi.entrez.html#topiary.ncbi.entrez.proteome.get_proteome)\n",
    "    + [topiary.ncbi.make_blast_db](https://topiary-asr.readthedocs.io/en/latest/topiary.ncbi.blast.html#topiary.ncbi.blast.make.make_blast_db)\n",
    "    + [topiary.recip_blast](https://topiary-asr.readthedocs.io/en/latest/topiary.ncbi.blast.html#module-topiary.ncbi.blast.recip)\n",
    "\n",
    "\n",
    "### Output:\n",
    "+ An updated topiary dataframe with reciprocal BLAST results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf78864",
   "metadata": {
    "id": "0cf78864"
   },
   "outputs": [],
   "source": [
    "# If you want to restart the pipeline *without* running the pipeline steps above, \n",
    "# please uncomment the following lines. If you want to force this step to be \n",
    "# species aware (or not) set species_aware=True (or False). \n",
    "\n",
    "# _, key_species, paralog_patterns, species_aware = topiary.io.read_seed(seed_spreadsheet_file,\n",
    "#                                                                        species_aware=None)\n",
    "# df = topiary.read_dataframe(\"01_initial-dataframe.csv\")\n",
    "\n",
    "\n",
    "# Create a list of proteomes to download\n",
    "key_proteomes = []\n",
    "for k in key_species:\n",
    "    get_proteome = topiary.ncbi.get_proteome(species=k)\n",
    "    key_proteomes.append(get_proteome)\n",
    "\n",
    "# Construct a blast database from the downloaded proteomes\n",
    "local_recip_blast_db = \"local_recip_blast_db\"\n",
    "topiary.ncbi.make_blast_db(key_proteomes,local_recip_blast_db)\n",
    "\n",
    "# Do reciprocal BLAST against the proteomes from the key species\n",
    "df = topiary.recip_blast(df,\n",
    "                         paralog_patterns=paralog_patterns,\n",
    "                         local_blast_db=local_recip_blast_db,\n",
    "                         ncbi_blast_db=None,\n",
    "                         ncbi_taxid=None,\n",
    "                         ignorecase=True,\n",
    "                         min_call_prob=0.95,\n",
    "                         partition_temp=1,\n",
    "                         drop_combo_fx=0.9,\n",
    "                         use_start_end=True,\n",
    "                         hitlist_size=10,\n",
    "                         e_value_cutoff=0.01,\n",
    "                         gapcosts=(11,1),\n",
    "                         num_threads=-1,\n",
    "                         keep_blast_xml=False)\n",
    "\n",
    "topiary.write_dataframe(df,\"02_recip-blast-dataframe.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390e55f6-ae05-4b4a-8b1b-ee71365d3238",
   "metadata": {},
   "source": [
    "### Things to look for in the output dataframe\n",
    "+ This dataframe should have the same number of sequences as the input dataframe; however, some of the sequences now have `keep = False`. This is because they failed to find reciprocal BLAST hits. \n",
    "+ The dataframe has five new columns (`recip_found_paralog`, `recip_hit`, `recip_paralog`, `recip_prob_match`, and `recip_bit_score`). For a full description of what these mean, see the [function documentation](https://topiary-asr.readthedocs.io/en/latest/topiary.ncbi.blast.html#module-topiary.ncbi.blast.recip). The most important two columns are `recip_paralog` (which indicates the paralog call) and `recip_prob_match` (which indicates our confidence in the call, where `1.0` is highly confident). \n",
    "\n",
    "## Remove redundant sequences. \n",
    "\n",
    "BLAST typically finds many more sequences than are necessary or practical for a standard phylogenetic analysis. We must therefore select sequences that sample the diversity in the dataset without compromising our ability to infer ancestors. Topiary selects a subset of sequences using a combination of taxonomy, sequence identity, and sequence quality (see [documentation](https://topiary-asr.readthedocs.io/en/latest/pipelines.html#seed-to-alignment)). The following code block decides how many sequences to put in the final alignment (`target_seq_number`), removes highly similar sequences from within each sequences (`shrink_in_species`), lowers overall redundancy (`shrink_redundant`), and removes the worst aligning sequences (`shrink_aligners`). \n",
    "\n",
    "\n",
    "### Inputs:\n",
    "+ This cell uses three inputs from the previous cell:\n",
    "    + `df`: The topiary dataframe holding current dataset\n",
    "    + `seqs_per_column`: number of sequences to include in the alignment per column in the seed dataset sequences. (If the largest seed sequence was 100 amino acids, a value of 2 would create an alignment with 200 sequences)\n",
    "+ For detailed descriptions of the arguments to the functions used, see the documentation:\n",
    "    + [topiary.quality.shrink_in_species](https://topiary-asr.readthedocs.io/en/latest/topiary.quality.html#topiary.quality.shrink.shrink_redundant)\n",
    "    + [topiary.quality.redundancy.find_redundancy_cutoff](https://topiary-asr.readthedocs.io/en/latest/topiary.quality.html#topiary.quality.redundancy.find_redundancy_cutoff)\n",
    "    + [topiary.quality.shrink_redundant](https://topiary-asr.readthedocs.io/en/latest/topiary.quality.html#topiary.quality.shrink.shrink_redundant)\n",
    "    + [topiary.quality.shrink_aligners](https://topiary-asr.readthedocs.io/en/latest/topiary.quality.html#topiary.quality.shrink.shrink_aligners)\n",
    "\n",
    "\n",
    "### Output:\n",
    "+ An updated topiary dataframe with lower sequence redundancy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47af8875",
   "metadata": {
    "id": "47af8875"
   },
   "outputs": [],
   "source": [
    "# If you want to restart the pipeline *without* running the pipeline steps above, \n",
    "# please uncomment the following lines. If you want to force this step to be \n",
    "# species aware (or not) set species_aware=True (or False). \n",
    "\n",
    "# _, _, _, species_aware = topiary.io.read_seed(seed_spreadsheet_file,species_aware=None)\n",
    "# df = topiary.read_dataframe(\"02_recip-blast-dataframe.csv\")\n",
    "\n",
    "\n",
    "# Determine how many sequences we are aiming for. This will aim to have 1 \n",
    "# sequence each site in the key sequence. \n",
    "seqs_per_column = 1\n",
    "key_sequences = df.loc[df.key_species,\"sequence\"]\n",
    "target_seq_number = int(np.round(np.max([len(s) for s in key_sequences])*seqs_per_column*1.1,0))\n",
    "\n",
    "# The first step is to remove highly similar sequences from the same species.\n",
    "# This removes things like splice variants, super recent duplications, etc.\n",
    "df = topiary.quality.shrink_in_species(df,\n",
    "                                       redundancy_cutoff=0.98)\n",
    "topiary.write_dataframe(df,\"03.0_shrunk-in-species.csv\")\n",
    "\n",
    "# If we are not species aware, we need to find a redundnacy cutoff that\n",
    "# will yield approximately the right number of sequences. \n",
    "if not species_aware:\n",
    "    redundancy_cutoff = topiary.quality.redundancy.find_redundancy_cutoff(df,\n",
    "                                                                          target_seq_number=target_seq_number)\n",
    "else:\n",
    "    redundancy_cutoff = 0.98\n",
    "\n",
    "# Remove redundant sequences. If species aware, this will remove sequences\n",
    "# using the sequence budgeting strategy described in Figure 4 of the \n",
    "# manuscript. (Redundancy cutoff will be ignored). Otherwise, remove based\n",
    "# on high sequence identity. \n",
    "df = topiary.quality.shrink_redundant(df,\n",
    "                                      paralog_column=\"recip_paralog\",\n",
    "                                      species_tree_aware=species_aware,\n",
    "                                      weighted_paralog_split=False,\n",
    "                                      merge_block_size=50,\n",
    "                                      redundancy_cutoff=redundancy_cutoff)\n",
    "topiary.write_dataframe(df,\"03.1_shrunk-redundant.csv\")\n",
    "\n",
    "# Remove the worst-aligning subset of sequences. \n",
    "df = topiary.quality.shrink_aligners(df,\n",
    "                                     target_seq_number,\n",
    "                                     paralog_column=\"recip_paralog\",\n",
    "                                     species_tree_aware=True,\n",
    "                                     weighted_paralog_split=False,\n",
    "                                     sparse_column_cutoff=0.80,\n",
    "                                     align_trim=(0.05,0.95))\n",
    "topiary.write_dataframe(df,\"03.2_shrunk-on-alignment.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbrMPMttawlg",
   "metadata": {
    "id": "bbrMPMttawlg"
   },
   "source": [
    "### Things to look for in the output dataframe\n",
    "The primary thing to note is that many more of the sequences will now have `keep = False`. These sequences were considered redundant and removed. If you want to bring back any sequences at this point, set `keep = True` for the row in question. This dataframe will also have several new columns indicating the relative quality of different sequences. \n",
    "\n",
    "## Alignment\n",
    "Topiary uses [Muscle5](https://www.drive5.com/muscle/) with its default parameters to generate a first draft of the multiple sequence alignment.\n",
    "\n",
    "### Inputs:\n",
    "+ This function requires only a topiary dataframe (`df` from the previous cell). \n",
    "+ The remaining arguments can bse used to control how muscle does the alignment. For a detailed description of how they work, see [topiary.muscle.align](https://topiary-asr.readthedocs.io/en/latest/topiary.muscle.html#module-topiary.muscle.muscle)\n",
    "\n",
    "### Output:\n",
    "+ An updated topiary dataframe with aligned sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e939721",
   "metadata": {
    "id": "6e939721"
   },
   "outputs": [],
   "source": [
    "# If you want to restart the pipeline *without* running the pipeline steps above, \n",
    "# please uncomment the following line.\n",
    "# df = topiary.read_dataframe(\"03.2_shrunk-on-alignment.csv\")\n",
    "\n",
    "df = topiary.muscle.align(input_seqs=df,\n",
    "                          output_fasta=None,\n",
    "                          super5=False,\n",
    "                          silent=False,\n",
    "                          muscle_cmd_args=[],\n",
    "                          muscle_binary=\"muscle\")\n",
    "topiary.write_dataframe(df,\"04_aligned-dataframe.csv\")\n",
    "\n",
    "# If you want to write out the alignment, you can uncomment the following line:\n",
    "# topiary.io.write_fasta(df,\"alignment.fasta\") \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9ee54a",
   "metadata": {
    "id": "fb9ee54a"
   },
   "source": [
    "### Things to look for in the output dataframe\n",
    "\n",
    "This function will create a new `alignment` column that has the sequences aligned.\n",
    "\n",
    "## Polish alignment and re-align\n",
    "\n",
    "In this final step, we remove sequences that have long insertions or are missing large chunks of the sequence. This prevents these poorly aligned sequences from disrupting the alignment of other sequences in the dataset. For details on how poorly aligned sequences are identified, see the [topiary documentation](https://topiary-asr.readthedocs.io/en/latest/topiary.quality.html#module-topiary.quality.polish). After removing poorly aligned sequences, this function aligns the sequences from scratch using Muscle5.  \n",
    "\n",
    "### Inputs:\n",
    "+ This function requires only a topiary dataframe (`df` from the previous cell). \n",
    "+ The remaining arguments can bse used to control how the alignment polishing is done. For a detailed description of the parameters and how they work, see [topiary.quality.polish](https://topiary-asr.readthedocs.io/en/latest/topiary.quality.html#module-topiary.quality.polish). \n",
    "\n",
    "### Output:\n",
    "+ An updated topiary dataframe poorly aligned sequences set to False. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79cb0dd",
   "metadata": {
    "id": "d79cb0dd"
   },
   "outputs": [],
   "source": [
    "# If you want to restart the pipeline *without* running the pipeline steps above, \n",
    "# please uncomment the following line.\n",
    "# df = topiary.read_dataframe(\"04_aligned-dataframe.csv\")\n",
    "\n",
    "# Run the polishing step\n",
    "df = topiary.quality.polish_alignment(df,\n",
    "                                      realign=True,\n",
    "                                      sparse_column_cutoff=0.80,\n",
    "                                      align_trim=(0,1),\n",
    "                                      fx_sparse_percentile=0.90,\n",
    "                                      sparse_run_percentile=0.90,\n",
    "                                      fx_missing_percentile=0.90)\n",
    "topiary.write_dataframe(df,\"05_clean-aligned-dataframe.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40607453-7ecf-4780-a19a-a320a18c3482",
   "metadata": {},
   "source": [
    "## Load in edited alignment\n",
    "\n",
    "In the [topiary protocol](file:///Users/harmsm/work/programming/git-clones/topiary/docs/build/html/protocol.html#visually-inspect-and-possibly-edit-the-alignment) we describe how we inspect and manually edit alignments. To do this, we need to write out a fasta file that can be loaded into a sequence viewer/editor. After doing those edits, we need to load the alignment back into the `alignment` column of our dataframe. The following two cells show how to do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9f356a-1cfa-4e5e-9f19-44e1cffe6206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to restart the pipeline *without* running the pipeline steps above, \n",
    "# please uncomment the following line.\n",
    "# df = topiary.read_dataframe(\"05_clean-aligned-dataframe.csv\")\n",
    "\n",
    "# Write a fasta file\n",
    "topiary.write_fasta(df,\n",
    "                    out_file=\"06_alignment.fasta\",\n",
    "                    seq_column=\"alignment\",\n",
    "                    label_columns=[\"species\",\"recip_paralog\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f693ab70-2fbb-41b5-9775-1628d8ce8e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to restart the pipeline *without* running the pipeline steps above, \n",
    "# please uncomment the following line.\n",
    "# df = topiary.read_dataframe(\"05_clean-aligned-dataframe.csv\")\n",
    "\n",
    "# Change this to point to a fasta file you edited and saved somewhere\n",
    "edited_fasta_file = \"06_alignment.fasta\" \n",
    "\n",
    "df = topiary.read_fasta_into(df,edited_fasta_file)\n",
    "topiary.write_dataframe(df,\"07_final-dataframe.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19908c4-30cf-4309-8f71-24068746f372",
   "metadata": {},
   "source": [
    "The file *07_final-dataframe.csv* is now ready for an ASR inference. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "_Eofl3tfskPS",
    "F8AxoYNCd0Ue"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
